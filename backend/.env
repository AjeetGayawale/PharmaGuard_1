# Ollama Configuration
# For local development, use:
OLLAMA_BASE_URL=http://localhost:11434/api/generate

# Model to use (recommended for 8GB RAM: llama3.2:3b)
OLLAMA_MODEL=llama3.2:3b

# Groq API key (get from https://console.groq.com/keys)
GROQ_API_KEY=YOUR_API_KEY_HERE
GROQ_MODEL=llama3.2:3b-instant